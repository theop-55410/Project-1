{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e56c229-47ad-4143-9ead-3c23f2ce7072",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from MCForecastTools import MCSimulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd63304",
   "metadata": {},
   "outputs": [],
   "source": [
    "startdate = '2017-01-01'\n",
    "enddate = '2017-01-31'\n",
    "BTC = f\"https://api.polygon.io/v2/aggs/ticker/X:BTCUSD/range/1/day/{startdate}/{enddate}?adjusted=true&sort=asc&limit=5000&apiKey=EuyLkPNR5tszoUvMnR5fZMjSdoBoNxIm\"\n",
    "ETH = f\"https://api.polygon.io/v2/aggs/ticker/X:ETHUSD/range/1/day/{startdate}/{enddate}?adjusted=true&sort=asc&limit=5000&apiKey=EuyLkPNR5tszoUvMnR5fZMjSdoBoNxIm\"\n",
    "LTC = f\"https://api.polygon.io/v2/aggs/ticker/X:LTCUSD/range/1/day/{startdate}/{enddate}?adjusted=true&sort=asc&limit=5000&apiKey=EuyLkPNR5tszoUvMnR5fZMjSdoBoNxIm\"\n",
    "DOGE = f\"https://api.polygon.io/v2/aggs/ticker/X:DOGEUSD/range/1/day/{startdate}/{enddate}?adjusted=true&sort=asc&limit=5000&apiKey=EuyLkPNR5tszoUvMnR5fZMjSdoBoNxIm\"\n",
    "SOL = f\"https://api.polygon.io/v2/aggs/ticker/X:SOLUSD/range/1/day/{startdate}/{enddate}?adjusted=true&sort=asc&limit=5000&apiKey=EuyLkPNR5tszoUvMnR5fZMjSdoBoNxIm\"\n",
    "DOT = f\"https://api.polygon.io/v2/aggs/ticker/X:DOTUSD/range/1/day/{startdate}/{enddate}?adjusted=true&sort=asc&limit=5000&apiKey=EuyLkPNR5tszoUvMnR5fZMjSdoBoNxIm\"\n",
    "BNB = f\"https://api.polygon.io/v2/aggs/ticker/X:BNBUSD/range/1/day/{startdate}/{enddate}?adjusted=true&sort=asc&limit=5000&apiKey=EuyLkPNR5tszoUvMnR5fZMjSdoBoNxIm\"\n",
    "UNI = f\"https://api.polygon.io/v2/aggs/ticker/X:UNIUSD/range/1/day/{startdate}/{enddate}?adjusted=true&sort=asc&limit=5000&apiKey=EuyLkPNR5tszoUvMnR5fZMjSdoBoNxIm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca004fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list = [BTC, ETH, LTC, DOGE]\n",
    "\n",
    "#url2_list = [SOL, DOT, BNB, UNI]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd6d08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that accepts a variable string URL for pulling the json response file from polygon\n",
    "def polygonurl(coinurl):\n",
    "        response = requests.get(coinurl).json()\n",
    "        return response\n",
    "\n",
    "#function for turning the json file into the dataframe with required columns\n",
    "def jsontodf(json):\n",
    "        df = pd.json_normalize(json, record_path =['results'],\n",
    "        meta =['ticker']\n",
    "        )\n",
    "        raw_data = pd.DataFrame(columns= [\"t\", \"o\", \"h\", \"l\", \"c\", \"v\", \"n\", \"vw\", \"ticker\"])\n",
    "        df = pd.concat([raw_data, df])\n",
    "        return df\n",
    "\n",
    "#function for structuring dataframe so MCsimulation will accept as input\n",
    "def structuredata(df):\n",
    "        df.columns = ['timestamp', 'open', 'high', 'low', 'close', 'volume', 'trade_count', 'vwap', 'symbol']\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
    "        df = df.set_index('timestamp')\n",
    "        col_names = [(df[\"symbol\"].iloc[0], x) for x in df.columns]\n",
    "        df.drop('symbol')\n",
    "        df.columns = pd.MultiIndex.from_tuples(col_names)\n",
    "        return df\n",
    "\n",
    "\n",
    "#function for saving an invidiual coin data as .csv, not currently being used\n",
    "def savetocsv(df):\n",
    "        filename = f'{df[\"symbol\"].iloc[0]}'\n",
    "        print(filename)\n",
    "        filepath = Path(f'{filename} + \".csv\"')\n",
    "        df.to_csv(filepath)\n",
    "\n",
    "#function to merge two dfs into MCsimulation format\n",
    "def merger(df1, df2):\n",
    "        df_merged = pd.merge(df1, df2, how = \"inner\", left_index=True, right_index=True)\n",
    "        return df_merged\n",
    "\n",
    "\n",
    "#run function that accepts a list of urls defined other variables needed for structuring the combined data\n",
    "def run(list, currentdf, counter):\n",
    "        if(list.index(counter) == 0):\n",
    "                response = polygonurl(i)\n",
    "                df = jsontodf(response)\n",
    "                df = structuredata(df)\n",
    "                #display(df.head())\n",
    "                #print('hi')\n",
    "                return df\n",
    "        else:        \n",
    "                response = polygonurl(i)\n",
    "                df = jsontodf(response)\n",
    "                df = structuredata(df)\n",
    "                df = merger(currentdf, df)\n",
    "                #display(df.head())\n",
    "                #print('ho')\n",
    "                return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c81c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cell for executing the data compiling functions\n",
    "\n",
    "MCdf = pd.DataFrame()\n",
    "\n",
    "#looping through the urls to build MCsimulation dataframe input\n",
    "for i in url_list:\n",
    "        MCdf = run(url_list, MCdf, i)\n",
    "\n",
    "display(MCdf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c897b7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the Monte Carlo simulation to forecast 30 years cumulative returns\n",
    "# The weights can be split in any fashion between tickers [BTC, ETH, LTC, DOGE, SOL, DOT, BNB, UNI]\n",
    "# Run 500 samples.\n",
    "MC_equal_weight = MCSimulation(\n",
    "    portfolio_data = MCdf,\n",
    "    weights = [.6, .2, .1, .1]\n",
    "    num_simulation = 500,\n",
    "    num_trading_days = 252*30\n",
    ")\n",
    "\n",
    "# Review the simulation input data\n",
    "# Printing the first five rows of the simulation input data\n",
    "MC_equal_weight.portfolio_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57d2b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "MC_equal_weight.calc_cumulative_return()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bdfcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MC_equal_weight_plot = MC_6040_weight.plot_simulation()\n",
    "MC_equal_weight_dist = MC_equal_weight.plot_distribution()\n",
    "MC_summary_stats = MC_equal_weight.summarize_cumulative_return()\n",
    "print(MC_summary_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582b78cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the lower and upper `95%` confidence intervals from the summary statistics,\n",
    "# calculate the range of the probable cumulative returns for a $500000 investment\n",
    "ci_95_lower_cumulative_return = MC_summary_stats[8] * 500000\n",
    "ci_95_upper_cumulative_return = MC_summary_stats[9] * 500000\n",
    "\n",
    "print(f\"There is a 95% chance that an initial investment of $500,000 in the portfolio\"\n",
    "    f\" over the next 5 years will end within in the range of\"\n",
    "    f\" ${ci_95_lower_cumulative_return: .2f} and ${ci_95_upper_cumulative_return: .2f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343daebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Although this result presents potentially fantastic news, it’s important to note that these five-year forecasted return values are based on only three years of historical price data. The five-year forecast simulates more variability than the data that the simulation is based on includes. In general, it’s ideal to supply one year of historical data for each year of simulated data.\n",
    "\n",
    "If we simulate using only small amounts of data during a recent time when markets are booming, or instead falling precipitously, a Monte-Carlo Analysis will inadvertently extrapolate this temporary market movement too far into the future. Getting data over a longer time period mitigates this effect. Due to the limitations of the Alpaca API, however, we can typically produce just three full years of historical data.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dev)",
   "language": "python",
   "name": "dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
